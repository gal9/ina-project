{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd  # Not a requirement of giotto-tda, but is compatible with the gtda.mapper module\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import open3d as o3d\n",
    "\n",
    "# Data viz\n",
    "from gtda.plotting import plot_point_cloud\n",
    "from gtda.plotting import plot_diagram\n",
    "\n",
    "# TDA magic\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.mapper import (\n",
    "    CubicalCover,\n",
    "    make_mapper_pipeline,\n",
    "    Projection,\n",
    "    plot_static_mapper_graph,\n",
    "    plot_interactive_mapper_graph,\n",
    "    MapperInteractivePlotter\n",
    ")\n",
    "\n",
    "# ML tools\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from src.feature_vectors import create_feature_vector\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare cloud points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority classifier accuracy: 0.693\n"
     ]
    }
   ],
   "source": [
    "def get_ply_files(folder):\n",
    "    files = list(filter(lambda file: file.split('.')[-1]=='ply', os.listdir(folder)))\n",
    "    files = list(map(lambda file: os.path.join(folder, file),files))\n",
    "    return files\n",
    "\n",
    "ply_files  = get_ply_files('data/tablesPly')\n",
    "ply_files += get_ply_files('data/chairsPly')\n",
    "ply_files += get_ply_files('data/octopusPly')\n",
    "ply_files += get_ply_files('data/spidersPly')\n",
    "\n",
    "# if (k == None) label each group differently \n",
    "# else label files in group k with True and others with False\n",
    "def label_groups(files, k):\n",
    "    group_sizes = [len([f for f in os.listdir('data/'+file) if f[-3:]=='ply']) for file in files]\n",
    "    group_sizes = [sum(group_sizes[:k]), group_sizes[k], sum(group_sizes[k+1:])]\n",
    "    # print(group_sizes)\n",
    "    labels = np.zeros(sum(group_sizes))\n",
    "    labels[group_sizes[0]:group_sizes[0]+group_sizes[1]] = 1\n",
    "        \n",
    "    return labels\n",
    "    \n",
    "files = ['tablesPly','chairsPly', 'octopusPly', 'spidersPly']\n",
    "labels = label_groups(files, 3)\n",
    "# print(labels)\n",
    "print(\"Majority classifier accuracy: %.3f\" % (1 - sum(labels)/len(labels)))\n",
    "\n",
    "pcd = [o3d.io.read_point_cloud(file) for file in ply_files]\n",
    "pcd = [np.asarray(pc.points) for pc in pcd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data for more accurate results\n",
    "shuffle_index = np.random.permutation(np.arange(0, len(labels)))\n",
    "labels = np.array(labels)\n",
    "pcd = np.array(pcd, dtype=object)\n",
    "labels = labels[shuffle_index]\n",
    "pcd = pcd[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistance and pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track connected components, loops, and voids\n",
    "homology_dimensions = [0, 1, 2]\n",
    "\n",
    "# Collapse edges to speed up H2 persistence calculation!\n",
    "persistence = VietorisRipsPersistence(\n",
    "    metric=\"euclidean\",\n",
    "    homology_dimensions=homology_dimensions,\n",
    "    n_jobs=6,\n",
    "    collapse_edges=True,\n",
    ")\n",
    "\n",
    "#filter_func = Projection(columns=[0,1,2])\n",
    "filter_func = PCA(n_components=2)\n",
    "\n",
    "cover = CubicalCover(n_intervals=4, overlap_frac=0.08)\n",
    "#cover = OneDimensionalCover(kind='uniform', n_intervals=10, overlap_frac=0.1)\n",
    "\n",
    "clusterer = DBSCAN(eps=10, metric=\"chebyshev\")\n",
    "\n",
    "n_jobs = 1\n",
    "\n",
    "pipe = make_mapper_pipeline(\n",
    "    filter_func=filter_func,\n",
    "    cover=cover,\n",
    "    clusterer=clusterer,\n",
    "    verbose=False,\n",
    "    n_jobs=n_jobs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature vector creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99%Time to compute create feature vectors: 91.40781569480896 s\n"
     ]
    }
   ],
   "source": [
    "entropy_feature_vectors = []\n",
    "feature_vectors = []\n",
    "start = time.time()\n",
    "for i, pc in enumerate(pcd):\n",
    "    print('\\r', f\"{int((i/len(pcd))*100)}%\", end=\"\")\n",
    "    e_fv, fv = create_feature_vector(pc, pipe, persistence)\n",
    "\n",
    "    entropy_feature_vectors.append(e_fv)\n",
    "    feature_vectors.append(fv)\n",
    "end = time.time()\n",
    "print(\"Time to compute create feature vectors:\", end - start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,\n",
       " [[0, 4.117647058823529, 0.25735294117647056, 0.5154061624649859],\n",
       "  [5, 3.75, 0.25, 0.4098214285714285],\n",
       "  [5, 3.6842105263157894, 0.2046783625730994, 0.44010025062656644],\n",
       "  [8, 3.5454545454545454, 0.16883116883116883, 0.39123376623376627],\n",
       "  [6, 3.5555555555555554, 0.2091503267973856, 0.47619047619047616],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [0, 5.0, 0.2631578947368421, 0.689047619047619],\n",
       "  [7, 3.238095238095238, 0.1619047619047619, 0.45986394557823135],\n",
       "  [5, 3.111111111111111, 0.18300653594771243, 0.2456349206349206],\n",
       "  [4, 3.125, 0.20833333333333334, 0.25],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [9, 3.0434782608695654, 0.1383399209486166, 0.34006211180124224],\n",
       "  [3, 3.5714285714285716, 0.27472527472527475, 0.6096938775510203],\n",
       "  [4, 3.125, 0.20833333333333334, 0.25],\n",
       "  [6, 3.619047619047619, 0.18095238095238095, 0.47063492063492063],\n",
       "  [5, 3.5, 0.18421052631578946, 0.4025],\n",
       "  [2, 3.125, 0.20833333333333334, 0.25],\n",
       "  [12, 2.5, 0.13157894736842105, 0.35],\n",
       "  [2, 4.0, 0.26666666666666666, 0.5571428571428572],\n",
       "  [7, 3.0, 0.17647058823529413, 0.4555555555555555],\n",
       "  [5, 3.6470588235294117, 0.22794117647058823, 0.5676470588235294],\n",
       "  [4, 3.125, 0.20833333333333334, 0.25],\n",
       "  [2, 4.333333333333333, 0.2549019607843137, 0.571031746031746],\n",
       "  [6, 3.066666666666667, 0.21904761904761907, 0.3323809523809524],\n",
       "  [3, 3.0588235294117645, 0.19117647058823528, 0.23529411764705882],\n",
       "  [2, 3.7142857142857144, 0.2857142857142857, 0.4755102040816327],\n",
       "  [6, 3.5555555555555554, 0.2091503267973856, 0.48055555555555557],\n",
       "  [2, 4.315789473684211, 0.23976608187134504, 0.5372180451127819],\n",
       "  [3, 3.2222222222222223, 0.1895424836601307, 0.19444444444444445],\n",
       "  [1, 4.428571428571429, 0.34065934065934067, 0.7005102040816327],\n",
       "  [2, 3.125, 0.20833333333333334, 0.25],\n",
       "  [4, 3.375, 0.225, 0.41607142857142854],\n",
       "  [5, 3.75, 0.25, 0.44732142857142854],\n",
       "  [0, 5.25, 0.35, 0.6571428571428571],\n",
       "  [3, 3.2857142857142856, 0.25274725274725274, 0.32346938775510203],\n",
       "  [12, 1.875, 0.125, 0.0],\n",
       "  [7, 3.619047619047619, 0.18095238095238095, 0.4801587301587301],\n",
       "  [2, 3.125, 0.20833333333333334, 0.25],\n",
       "  [7, 3.0, 0.2, 0.31249999999999994],\n",
       "  [7, 3.2941176470588234, 0.20588235294117646, 0.3558823529411765],\n",
       "  [6, 3.2941176470588234, 0.20588235294117646, 0.44873949579831934],\n",
       "  [6, 3.375, 0.225, 0.30089285714285713],\n",
       "  [0, 5.294117647058823, 0.33088235294117646, 0.6671335200746965],\n",
       "  [7, 3.1578947368421053, 0.17543859649122806, 0.4343358395989975],\n",
       "  [8, 2.375, 0.15833333333333333, 0.075],\n",
       "  [3, 4.222222222222222, 0.24836601307189543, 0.5828042328042328],\n",
       "  [0, 4.352941176470588, 0.27205882352941174, 0.49187675070028014],\n",
       "  [5, 3.8947368421052633, 0.21637426900584797, 0.4010025062656641],\n",
       "  [7, 3.2941176470588234, 0.20588235294117646, 0.3558823529411765],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [8, 3.142857142857143, 0.15714285714285714, 0.56005291005291],\n",
       "  [10, 2.9166666666666665, 0.12681159420289853, 0.27291666666666664],\n",
       "  [7, 3.4, 0.17894736842105263, 0.5676190476190477],\n",
       "  [5, 3.789473684210526, 0.21052631578947367, 0.5075187969924813],\n",
       "  [7, 3.619047619047619, 0.18095238095238095, 0.55],\n",
       "  [12, 1.875, 0.125, 0.0],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [2, 3.5555555555555554, 0.2091503267973856, 0.36587301587301585],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [6, 3.2941176470588234, 0.20588235294117646, 0.4627450980392157],\n",
       "  [2, 3.125, 0.20833333333333334, 0.25],\n",
       "  [4, 2.769230769230769, 0.23076923076923075, 0.25274725274725274],\n",
       "  [0, 5.25, 0.35, 0.6571428571428571],\n",
       "  [2, 3.875, 0.25833333333333336, 0.42857142857142855],\n",
       "  [2, 4.888888888888889, 0.28758169934640526, 0.5285714285714286],\n",
       "  [6, 3.473684210526316, 0.1929824561403509, 0.44962406015037604],\n",
       "  [2, 3.375, 0.225, 0.22499999999999998],\n",
       "  [2, 3.125, 0.20833333333333334, 0.25],\n",
       "  [5, 3.473684210526316, 0.1929824561403509, 0.6469924812030076],\n",
       "  [6, 2.6666666666666665, 0.19047619047619047, 0.2866666666666667],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [6, 3.473684210526316, 0.1929824561403509, 0.5144110275689223],\n",
       "  [5, 3.5789473684210527, 0.19883040935672514, 0.48922305764411034],\n",
       "  [5, 3.125, 0.20833333333333334, 0.375],\n",
       "  [3, 4.111111111111111, 0.2418300653594771, 0.5281746031746031],\n",
       "  [4, 3.7, 0.19473684210526318, 0.618452380952381],\n",
       "  [6, 3.2222222222222223, 0.1895424836601307, 0.4417989417989418],\n",
       "  [0, 5.25, 0.35, 0.6571428571428571],\n",
       "  [2, 3.1666666666666665, 0.28787878787878785, 0.2833333333333333],\n",
       "  [5, 3.2941176470588234, 0.20588235294117646, 0.5512605042016807],\n",
       "  [6, 3.2222222222222223, 0.1895424836601307, 0.517063492063492],\n",
       "  [6, 2.7142857142857144, 0.2087912087912088, 0.24285714285714285],\n",
       "  [4, 4.105263157894737, 0.2280701754385965, 0.6429824561403509],\n",
       "  [2, 3.7777777777777777, 0.2222222222222222, 0.42460317460317465],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [2, 3.875, 0.25833333333333336, 0.42857142857142855],\n",
       "  [0, 5.25, 0.35, 0.6571428571428571],\n",
       "  [0, 5.25, 0.35, 0.6571428571428571],\n",
       "  [8, 3.3333333333333335, 0.16666666666666669, 0.4765306122448979],\n",
       "  [0, 5.25, 0.35, 0.6571428571428571],\n",
       "  [4, 3.8666666666666667, 0.2761904761904762, 0.4904761904761905],\n",
       "  [5, 3.3333333333333335, 0.19607843137254902, 0.30158730158730157],\n",
       "  [10, 3.0, 0.14285714285714285, 0.2844155844155844],\n",
       "  [4, 3.411764705882353, 0.21323529411764705, 0.39705882352941174],\n",
       "  [3, 4.0, 0.23529411764705882, 0.517063492063492],\n",
       "  [0, 5.25, 0.35, 0.657142857142857],\n",
       "  [6, 3.739130434782609, 0.1699604743083004, 0.7017598343685301],\n",
       "  [7, 3.3, 0.17368421052631577, 0.42857142857142855],\n",
       "  [6, 3.2222222222222223, 0.1895424836601307, 0.48928571428571427],\n",
       "  [0, 5.25, 0.35, 0.657142857142857]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pcd), feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With homologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69 accuracy with a standard deviation of 0.02  Homology1\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (2,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (3,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 1)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 2)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 2)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (2, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 1, 2)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 1, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 2, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 2, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Homology2\n",
      "0.68 accuracy with a standard deviation of 0.03  Combination of features (0,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (2,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (3,)\n",
      "0.68 accuracy with a standard deviation of 0.03  Combination of features (0, 1)\n",
      "0.68 accuracy with a standard deviation of 0.03  Combination of features (0, 2)\n",
      "0.68 accuracy with a standard deviation of 0.03  Combination of features (0, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 2)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (2, 3)\n",
      "0.68 accuracy with a standard deviation of 0.03  Combination of features (0, 1, 2)\n",
      "0.68 accuracy with a standard deviation of 0.03  Combination of features (0, 1, 3)\n",
      "0.68 accuracy with a standard deviation of 0.03  Combination of features (0, 2, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 2, 3)\n",
      "0.72 accuracy with a standard deviation of 0.04  Homology3\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (0,)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (1,)\n",
      "0.72 accuracy with a standard deviation of 0.04  Combination of features (2,)\n",
      "0.72 accuracy with a standard deviation of 0.04  Combination of features (3,)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (0, 1)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (0, 2)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (0, 3)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (1, 2)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (1, 3)\n",
      "0.72 accuracy with a standard deviation of 0.04  Combination of features (2, 3)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (0, 1, 2)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (0, 1, 3)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (0, 2, 3)\n",
      "0.73 accuracy with a standard deviation of 0.05  Combination of features (1, 2, 3)\n",
      "\n",
      "Average score: 0.7040\n",
      "Best scores: [(0.7318181818181818, '(1,) 3'), (0.7318181818181818, '(1, 3) 3'), (0.7318181818181818, '(1, 2, 3) 3')]\n"
     ]
    }
   ],
   "source": [
    "num_features = len(feature_vectors[0])\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "best_scores = []\n",
    "# We take one homology and up to three other features\n",
    "\n",
    "for homology_idx in range(3):\n",
    "    final_fvs = []\n",
    "    \n",
    "    # First add homology and nothing else\n",
    "    for entropy_fv in entropy_feature_vectors:\n",
    "        final_fvs.append(entropy_fv[homology_idx])\n",
    "\n",
    "    # TODO add train and test\n",
    "    scores = cross_val_score(clf, final_fvs, labels, cv=10)\n",
    "    best_scores.append((scores.mean(), \"Homology\"+str(homology_idx+1)))\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f  %s\" % (scores.mean(), scores.std(), \"Homology\"+str(homology_idx+1)))\n",
    "\n",
    "    for number_of_additional_features in range(1,4):\n",
    "        combinations = list(itertools.combinations(range(num_features), number_of_additional_features))\n",
    "\n",
    "        # Loop through all posible feature subsets of size\n",
    "        for combination in combinations:\n",
    "            # print(combination)\n",
    "            final_fvs = []\n",
    "            # First add homology and a certain number of features\n",
    "            for fv_idx, entropy_fv in enumerate(entropy_feature_vectors):\n",
    "                extracted_fv = [x for x in entropy_fv[homology_idx]]\n",
    "\n",
    "                extracted_fv += [feature_vectors[fv_idx][i] for i in combination]\n",
    "\n",
    "                final_fvs.append(extracted_fv)\n",
    "\n",
    "            # TODO add train and test\n",
    "            scores = cross_val_score(clf, final_fvs, labels, cv=10)\n",
    "            best_scores.append((scores.mean(), str(combination) + \" \" + str(homology_idx+1)))\n",
    "            print(\"%0.2f accuracy with a standard deviation of %0.2f  %s\" % (scores.mean(), scores.std(), \"Combination of features \"+str(combination)))\n",
    "\n",
    "            # print(final_fvs)\n",
    "            \n",
    "best_scores.sort(reverse=True)\n",
    "print(\"\\nAverage score: %0.4f\" % (sum([x for x, s in best_scores]) / len(best_scores)))\n",
    "print(\"Best scores:\", best_scores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_fvs, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "SVM.predict(X_test)\n",
    "round(SVM.score(X_test,y_test), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without homologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (2,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (3,)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 1)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 2)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 2)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (2, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 1, 2)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 1, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 2, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (1, 2, 3)\n",
      "0.69 accuracy with a standard deviation of 0.02  Combination of features (0, 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "for number_of_additional_features in range(1,6):\n",
    "    combinations = list(itertools.combinations(range(num_features), number_of_additional_features))\n",
    "\n",
    "    # Loop through all posible feature subsets of size\n",
    "    for combination in combinations:\n",
    "        # print(combination)\n",
    "        final_fvs = []\n",
    "        # First add homology and a certain number of features\n",
    "        for fv_idx, fv in enumerate(feature_vectors):\n",
    "            extracted_fv = [fv[i] for i in combination]\n",
    "\n",
    "            final_fvs.append(extracted_fv)\n",
    "\n",
    "        # TODO add train and test\n",
    "        scores = cross_val_score(clf, final_fvs, labels, cv=10)\n",
    "        best_scores.append((scores.mean(), str(combination) + \" \" + str(homology_idx)))\n",
    "        print(\"%0.2f accuracy with a standard deviation of %0.2f  %s\" % (scores.mean(), scores.std(), \"Combination of features \"+str(combination)))\n",
    "\n",
    "        # print(final_fvs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_fvs, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "SVM.predict(X_test)\n",
    "round(SVM.score(X_test,y_test), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1faa2b89841f2d81216e2b69e9280f066c9505dc0dde4939c230224824eed47"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
